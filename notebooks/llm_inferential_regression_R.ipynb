{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7HaLsckEYbSm6gdYycyYg"
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using Large Language Models for Inferential Regression Modelling in Social Sciences\n",
        "\n",
        "\n",
        "In this tutorial, we look at the following regression model:\n",
        "\n",
        "`performace ~ 1 + specificity`\n",
        "\n",
        "That is, we regress student performances on specificity scores.\n",
        "\n",
        "First, we're going to simulate some data for performance and specificity. With this simulated dataset, we can investigate how measurement error affects regression results.\n",
        "\n",
        "Second, we're going to learn how to correct for measurement error with Gabrielle Martins van Jaarsveld's SoDa fellowship dataset."
      ],
      "metadata": {
        "id": "PHhOlhjzjH0H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Warning!\n",
        "\n",
        "Before you proceed, please note that the Google Colab Environment makes it difficult/impossible to install R packages directly from GitHub. This is inconvenient for us because all we are going to work with the `dsl` package which is great for correcting measurement error in regression models but has to be installed from GitHub.\n",
        "\n",
        "For this consideration, we suggest that you run the code in this notebook on your **local computer environment (e.g., RStudio)** instead."
      ],
      "metadata": {
        "id": "5jE2PM0HP37-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "if(!require(tidyverse)) install.packages(\"tidyverse\")\n",
        "if(!require(gridExtra)) install.packages(\"gridExtra\")\n",
        "if(!require(devtools)) install.packages(\"devtools\")\n",
        "library(devtools)\n",
        "install_github(\"naoki-egami/dsl\", dependencies = TRUE)"
      ],
      "metadata": {
        "id": "idXloT2iMzMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load required packages\n",
        "library(tidyverse)\n",
        "library(gridExtra)\n",
        "library(dsl)"
      ],
      "metadata": {
        "id": "CXgiUUMHRKD_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Influence of measurement error on regression modelling"
      ],
      "metadata": {
        "id": "YlP29bfvkW1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's simulate some data."
      ],
      "metadata": {
        "id": "0gIMd6UctozM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(42)  # Set seed for reproducibility\n",
        "\n",
        "# Simulate true X (specificity) and Y (performance)\n",
        "n <- 100\n",
        "x_true <- sample(0:2, n, replace = TRUE)\n",
        "beta <- 0.5  # True regression coefficient\n",
        "intercept <- 0\n",
        "y <- intercept + beta * x_true + rnorm(n, mean = 0, sd = 0.1)  # Adding noise to y"
      ],
      "metadata": {
        "id": "ToyS-PmvSNWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introduce systematic and random error into the predictor x."
      ],
      "metadata": {
        "id": "Oh2SqEO_tuzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Introduce measurement errors\n",
        "systematic_error <- 1  # Systematic shift in x\n",
        "random_error <- rnorm(n, mean = 0, sd = 1)  # Random error\n",
        "\n",
        "x_systematic <- x_true + systematic_error  # X with systematic measurement error\n",
        "x_random <- round(x_true + random_error)  # X with random measurement error\n",
        "x_random[x_random < 0] <- 0  # Ensure values are within range\n",
        "x_random[x_random > 2] <- 2"
      ],
      "metadata": {
        "id": "-2k687FNtvO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Influence of systematic error in regression modelling"
      ],
      "metadata": {
        "id": "HxIA_W5V1lBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to fit and plot regression\n",
        "plot_regression <- function(x, y, label, x_ticks) {\n",
        "  model <- lm(y ~ x)  # Fit linear model\n",
        "\n",
        "  # Scatter plot with regression line\n",
        "  library(ggplot2)\n",
        "  plot <- ggplot(data.frame(x, y), aes(x = x, y = y)) +\n",
        "    geom_point(size = 2) +\n",
        "    geom_smooth(method = \"lm\", se = TRUE, color = \"blue\") +\n",
        "    labs(title = paste0(label, \"\\nEstimated Î² = \", round(coef(model)[2], 2)),\n",
        "         x = \"X: Specificity\",\n",
        "         y = \"Y: Performance\") +\n",
        "    scale_x_continuous(breaks = x_ticks)\n",
        "\n",
        "  return(plot)\n",
        "}"
      ],
      "metadata": {
        "id": "I1t2nInZV0Mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create plots\n",
        "\n",
        "p1 <- plot_regression(x_true, y, \"True X (No Measurement Error)\", c(0,1,2,3))\n",
        "p2 <- plot_regression(x_systematic, y, \"X with Systematic Measurement Error\", c(0,1,2,3))\n",
        "\n",
        "grid.arrange(p1, p2, ncol = 2)"
      ],
      "metadata": {
        "id": "9Ch17K6kWHFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Influence of random error in regression modelling"
      ],
      "metadata": {
        "id": "ub0p5kM0uGSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot X with random measurement error\n",
        "p3 <- plot_regression(x_random, y, \"X with Random Measurement Error\", c(0,1,2))\n",
        "\n",
        "grid.arrange(p1, p3, ncol = 2)"
      ],
      "metadata": {
        "id": "ep_t8iR4WaDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correcting measurement error in regression with the DSL package"
      ],
      "metadata": {
        "id": "sNvFyv4-kgDK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have seen how measurement errror can affect statistical modelling, let's try to correct for it!\n",
        "\n",
        "We will use the same toy dataset as in the previous tutorial, which comes from Gabrielle Martins van Jaarsveld's SoDa fellowship project on annotating markers of self-regulated learning from student conversation data. Feel free to use your own data.\n",
        "\n",
        "For R users, the `DSL` package comes in handy for this purpose. Note that `DSL` can handle measurement error in both the predictors as well as the outcome variable in a regression model.\n",
        "\n",
        "Unfortunately, there is no existing **Python** package that can handle measurement error in predictors of regression model. To keep both the R and the Python notebooks consistent with each other, we are going to assume measurement error only in the outcome variable for the regression analysis we are going to conduct next.\n",
        "\n",
        "For alternatives, see below or check out https://github.com/sodascience/social_science_inferences_with_llms"
      ],
      "metadata": {
        "id": "lLj_1jfpWzqo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Software Packages\n",
        "| Name | Method | Language | Estimators | Predicted Variables |\n",
        "|----|----|----|----|----|\n",
        "| [PostPI](https://github.com/leekgroup/postpi) | Post-Prediction Inference | R | Means, quantitles and GLMs | Outcome |\n",
        "| [PPI, PPI++, Cross-PPI, PPBoot](https://github.com/aangelopoulos/ppi_py) | Prediction-powered inference and its extensions | Python | Any arbitrary estimator | Outcome |\n",
        "| [PSPA](https://github.com/qlu-lab/pspa) | PoSt-Prediction Adaptive inference | R | Means, quantiles, linear regression, logistic regression | Predictor and outcome |\n",
        "| [ipd](https://github.com/ipd-tools/ipd) | Implemented PostPI, PPI, PPI++ and PSPA | R | Means, quantiles, linear regression, logistic regression | Outcome |\n",
        "| [PSPS](https://github.com/qlu-lab/psps) | PoSt-Prediction Summary-statistics-based (PSPS) inference | R and Python | M-estimators | Outcome |\n",
        "| [DSL](https://naokiegami.com/dsl/) | Design-based Supervised Learning | R | Moment-based estimators | Predictor and outcome |\n"
      ],
      "metadata": {
        "id": "wt9IzvXH648t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data loading"
      ],
      "metadata": {
        "id": "RdTmthVQR46t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Sheets export link\n",
        "sheet_url <- \"https://docs.google.com/spreadsheets/d/1yLKp2HYW2gPlJv1kyqjjr1qLtOA-O5pPGttAMX5wvbY/export?format=csv\"\n",
        "\n",
        "# Read CSV into DataFrame\n",
        "df <- read_csv(sheet_url)"
      ],
      "metadata": {
        "id": "w6iO_UFkm2aQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build a gold dataset and regression"
      ],
      "metadata": {
        "id": "-Igredot697e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's build a subset of Gabrielle's dataset that contains only gold labels (i.e., error-free measurements)."
      ],
      "metadata": {
        "id": "i0wWsmI2XRvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_gold <- df |>\n",
        "  filter(!is.na(score_specificity_human), !is.na(performance)) |>\n",
        "  slice(rep(1:n(), each = 5))  # Expanding the dataset 5 times\n",
        "\n",
        "gold_fit <- lm(performance ~ score_specificity_human, data = df_gold)\n",
        "summary(gold_fit)\n",
        "confint(gold_fit)"
      ],
      "metadata": {
        "id": "RB-E7OFGawb6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know now that for these observations, the gold regression coefficient is 0.337 with a confidence interval of [0.060, 0.614] and statistical significance at 0.05 alpha level."
      ],
      "metadata": {
        "id": "Vv8_jy742X31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To proceed with the assumption that we only correct for measurement error in the outcome variable of the regression model (instead of the predictor variable), let's also assume that:\n",
        "\n",
        "1. The specificity measurements (i.e., the predictor) are completely observed and error free;\n",
        "2. In contrast, the performance measurements (i.e., the outcome variable) are only partially observed (i.e., we only have partial labels) and for the unobserved y values, we have their corresponding predictions (y_hat), which can come from LLMs and likely suffer from measurement error. To simplify our analysis, we will manually make these predictions instead of using LLMs."
      ],
      "metadata": {
        "id": "kur6uVLW2zVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create performance predictions and data partitions"
      ],
      "metadata": {
        "id": "rurEAK2e7Mbl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a predicted performance variable (`performance_pred`) by introducing measurement error into the original `performance` variable."
      ],
      "metadata": {
        "id": "D0FxY_IaZcfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(42)\n",
        "bias <- 1\n",
        "\n",
        "df_gold <- df_gold |>\n",
        "  mutate(performance_pred = performance - bias + rnorm(n(), mean = 0, sd = 0.5))"
      ],
      "metadata": {
        "id": "cqoaaFWV398k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We shuffle the dataset and split it into two partitions: `df_observed` where we have both error-free measurements and predictions, and `df_unobserved` where we have only predictions."
      ],
      "metadata": {
        "id": "RghQyW5lZviV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(1)\n",
        "df_gold_shuffled <- df_gold |>\n",
        "  sample_frac(1, replace = FALSE)  # Shuffle rows\n",
        "\n",
        "p_unobserved_y <- 0.5\n",
        "n_unobserved_y <- floor(p_unobserved_y * nrow(df_gold))\n",
        "\n",
        "df_observed <- df_gold_shuffled |> slice(1:(n() - n_unobserved_y))\n",
        "df_unobserved <- df_gold_shuffled |> slice((n() - n_unobserved_y + 1):n())"
      ],
      "metadata": {
        "id": "nWDfzAejZvxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Regression model with observed partition"
      ],
      "metadata": {
        "id": "kWhGQXui7XqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happens if we run a regression model on the observed partition? That is, we ignore all the prediction-based data."
      ],
      "metadata": {
        "id": "rqMhzAszaHkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "observed_fit <- lm(performance ~ score_specificity_human, data = df_observed)\n",
        "summary(observed_fit)\n",
        "confint(observed_fit)"
      ],
      "metadata": {
        "id": "mwJg0r2ickPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can see that the regression coefficient is estimated to be 0.407, much bigger than the gold value 0.337 and is no longer statistically significant at 0.05 alpha level. The confidence interval also now contains zero."
      ],
      "metadata": {
        "id": "qPWkl5FaaQKS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Corrected regression model on all data using `dsl`"
      ],
      "metadata": {
        "id": "V_QCMpGX7pLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the `dsl` package to correct our regression estimates, we need to prepare a new dataset where on the outcome variable we have missing gold labels."
      ],
      "metadata": {
        "id": "JOMF1bXDa2-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_dsl <- df_unobserved |>\n",
        "  mutate(performance = NA) |>\n",
        "  bind_rows(df_observed)"
      ],
      "metadata": {
        "id": "t8c2rGQS6Exx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_lm <- dsl(model = \"lm\",\n",
        "              formula = performance ~ score_specificity_human,\n",
        "              predicted_var = \"performance\",\n",
        "              prediction = \"performance_pred\",\n",
        "              data = df_dsl)\n",
        "summary(out_lm)"
      ],
      "metadata": {
        "id": "IRqaMkDs5R8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the corrected regression estimate (0.324) is closer than the uncorrected one (0.407) to the true value (0.337).\n",
        "\n",
        "We can also see that the confidence interval no longer contains zero, which also indicates likely statistical significance at 0.05 alpha level."
      ],
      "metadata": {
        "id": "YD1CAsq5buu4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise: Try your own data!"
      ],
      "metadata": {
        "id": "d9cLrQChBNXO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's write some code!"
      ],
      "metadata": {
        "id": "FdA9iOorB4o7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}